# DQN Algorithm Configuration
algorithm:
  type: "DQN"
  name: "Deep Q-Network"

# Network architecture
network:
  type: "QNetwork"
  hidden_size: 64
  learning_rate: 0.001
  optimizer: "Adam"
  weight_decay: 0.0001

# Training parameters
training:
  batch_size: 64
  gamma: 0.99
  epsilon: 0.1
  epsilon_decay: 0.997
  epsilon_min: 0.05
  metrics:
    window_size: 100
  
# Algorithm-specific parameters
dqn_specific:
  target_update_freq: 100
  buffer_size: 50000
  min_buffer_size: 1000
  gradient_clip: 1.0
  
# Experience replay
replay_buffer:
  type: "ReplayBuffer"
  max_size: 10000
  min_size: 1000
  
# Loss function
loss:
  type: "MSE"
  reduction: "mean"
  
# Training loop
training_loop:
  update_freq: 4  # Update every 4 steps
  max_grad_norm: 1.0
  
# Evaluation
evaluation:
  eval_freq: 1000  # Evaluate every 1000 episodes
  eval_episodes: 10
  render: false 